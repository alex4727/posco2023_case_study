{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sd1/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from resnet import resnet18\n",
    "from utils import BalancedSoftmax, CustomDataset, AverageMeter, accuracy, add_to_confusion_matrix, get_per_class_results, make_deterministic, save_ckpt, load_ckpt\n",
    "\n",
    "\n",
    "use_pretrained = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataset_path = \"/root/data/posco_data/places10_LT/train\"\n",
    "valid_dataset_path = \"/root/data/posco_data/places10_LT/valid\"\n",
    "run_name = \"resnet18_places10_LT_balanced_softmax\"\n",
    "\n",
    "batch_size = 64\n",
    "total_epochs = 30\n",
    "lr_steps = [10, 20, 25]\n",
    "make_deterministic(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "if use_pretrained:\n",
    "    model = resnet18(pretrained=True, num_classes=1000).to(device)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10).to(device)\n",
    "else:\n",
    "    model = resnet18(num_classes=10).to(device)\n",
    "\n",
    "\n",
    "# Make Dataset & DataLoader\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_dataset = CustomDataset(dataset_path=train_dataset_path, transform=train_transforms, use_randaug=True)\n",
    "valid_dataset = CustomDataset(dataset_path=valid_dataset_path, transform=valid_transforms, use_randaug=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "# Make Optimizer & Loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), 1e-2, momentum=0.9, weight_decay=2e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_steps, gamma=0.1)\n",
    "criterion = BalancedSoftmax(samples_per_class=[1000, 555, 308, 170, 94, 52, 29, 16, 9, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, train_loader, model, criterion, optimizer, scheduler, epoch, turn_on_wandb=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    losses, top1, top5 = AverageMeter(device), AverageMeter(device), AverageMeter(device)\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = accuracy(outputs, labels , topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(prec1.item(), images.size(0))\n",
    "        top5.update(prec5.item(), images.size(0))\n",
    "\n",
    "    end_time = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"==================== Train Summary: Epoch {epoch+1} ====================\", flush=True)\n",
    "    print(f\"Train Epoch Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))}\", flush=True)\n",
    "    print(f\"Loss: {losses.avg:.2f}\\t Prec@1: {top1.avg:.2f}\\t Prec@5: {top5.avg:.2f}\", flush=True)\n",
    "    if turn_on_wandb:\n",
    "        wandb.log({\"train/loss\": losses.avg, \"train/top1\": top1.avg, \"train/top5\": top5.avg}, step=epoch+1)\n",
    "\n",
    "\n",
    "def validate(device, valid_loader, model, criterion, epoch, turn_on_wandb=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    losses, top1, top5 = AverageMeter(device), AverageMeter(device), AverageMeter(device)\n",
    "    model.eval()\n",
    "    confusion_matrix = torch.zeros(10, 10).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            prec1, prec5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "            confusion_matrix = add_to_confusion_matrix(confusion_matrix, outputs, labels)\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(prec1.item(), images.size(0))\n",
    "            top5.update(prec5.item(), images.size(0))\n",
    "\n",
    "    end_time = time.time()\n",
    "    per_class_results = get_per_class_results(confusion_matrix)\n",
    "    print(f\"==================== Valid Summary: Epoch {epoch+1} ====================\", flush=True)\n",
    "    print(f\"Valid Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))}\", flush=True)\n",
    "    print(f\"Loss: {losses.avg:.2f}\\t Prec@1: {top1.avg:.2f}\\t Prec@5: {top5.avg:.2f}\", flush=True)\n",
    "    if turn_on_wandb:\n",
    "        wandb.log({\"valid/loss\": losses.avg, \"valid/top1\": top1.avg, \"valid/top5\": top5.avg}, step=epoch+1)\n",
    "    return top1.avg, per_class_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malex4727\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/code/posco2023_case_study/wandb/run-20230711_220443-g0uiwy83</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alex4727/posco2023/runs/g0uiwy83' target=\"_blank\">resnet18_places10_LT_balanced_softmax</a></strong> to <a href='https://wandb.ai/alex4727/posco2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alex4727/posco2023' target=\"_blank\">https://wandb.ai/alex4727/posco2023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alex4727/posco2023/runs/g0uiwy83' target=\"_blank\">https://wandb.ai/alex4727/posco2023/runs/g0uiwy83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Train Summary: Epoch 1 ====================\n",
      "Train Epoch Elapsed time: 00:00:03\n",
      "Loss: 0.73\t Prec@1: 64.92\t Prec@5: 85.52\n",
      "==================== Valid Summary: Epoch 1 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 1.83\t Prec@1: 64.70\t Prec@5: 97.20\n",
      "Best Prec@1: 64.70 at epoch 1\n",
      "==================== Train Summary: Epoch 2 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.45\t Prec@1: 78.82\t Prec@5: 93.48\n",
      "==================== Valid Summary: Epoch 2 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 1.62\t Prec@1: 71.20\t Prec@5: 97.40\n",
      "Best Prec@1: 71.20 at epoch 2\n",
      "==================== Train Summary: Epoch 3 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.38\t Prec@1: 79.22\t Prec@5: 95.04\n",
      "==================== Valid Summary: Epoch 3 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 1.36\t Prec@1: 69.60\t Prec@5: 97.90\n",
      "Best Prec@1: 71.20 at epoch 2\n",
      "==================== Train Summary: Epoch 4 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.34\t Prec@1: 80.65\t Prec@5: 96.20\n",
      "==================== Valid Summary: Epoch 4 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 1.39\t Prec@1: 78.60\t Prec@5: 98.00\n",
      "Best Prec@1: 78.60 at epoch 4\n",
      "==================== Train Summary: Epoch 5 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.27\t Prec@1: 84.58\t Prec@5: 97.01\n",
      "==================== Valid Summary: Epoch 5 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.90\t Prec@1: 79.60\t Prec@5: 98.80\n",
      "Best Prec@1: 79.60 at epoch 5\n",
      "==================== Train Summary: Epoch 6 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.27\t Prec@1: 83.51\t Prec@5: 96.69\n",
      "==================== Valid Summary: Epoch 6 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 1.24\t Prec@1: 78.60\t Prec@5: 97.60\n",
      "Best Prec@1: 79.60 at epoch 5\n",
      "==================== Train Summary: Epoch 7 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.26\t Prec@1: 84.99\t Prec@5: 97.27\n",
      "==================== Valid Summary: Epoch 7 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.96\t Prec@1: 81.30\t Prec@5: 98.70\n",
      "Best Prec@1: 81.30 at epoch 7\n",
      "==================== Train Summary: Epoch 8 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.24\t Prec@1: 87.67\t Prec@5: 97.45\n",
      "==================== Valid Summary: Epoch 8 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.93\t Prec@1: 80.20\t Prec@5: 97.80\n",
      "Best Prec@1: 81.30 at epoch 7\n",
      "==================== Train Summary: Epoch 9 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.24\t Prec@1: 86.91\t Prec@5: 97.59\n",
      "==================== Valid Summary: Epoch 9 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.96\t Prec@1: 81.20\t Prec@5: 98.60\n",
      "Best Prec@1: 81.30 at epoch 7\n",
      "==================== Train Summary: Epoch 10 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.24\t Prec@1: 85.52\t Prec@5: 97.81\n",
      "==================== Valid Summary: Epoch 10 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 1.46\t Prec@1: 71.60\t Prec@5: 98.60\n",
      "Best Prec@1: 81.30 at epoch 7\n",
      "==================== Train Summary: Epoch 11 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.21\t Prec@1: 89.72\t Prec@5: 98.39\n",
      "==================== Valid Summary: Epoch 11 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.88\t Prec@1: 84.20\t Prec@5: 99.00\n",
      "Best Prec@1: 84.20 at epoch 11\n",
      "==================== Train Summary: Epoch 12 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.17\t Prec@1: 89.68\t Prec@5: 98.70\n",
      "==================== Valid Summary: Epoch 12 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.78\t Prec@1: 85.50\t Prec@5: 98.60\n",
      "Best Prec@1: 85.50 at epoch 12\n",
      "==================== Train Summary: Epoch 13 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.16\t Prec@1: 89.90\t Prec@5: 98.70\n",
      "==================== Valid Summary: Epoch 13 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.79\t Prec@1: 85.20\t Prec@5: 98.70\n",
      "Best Prec@1: 85.50 at epoch 12\n",
      "==================== Train Summary: Epoch 14 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.15\t Prec@1: 91.11\t Prec@5: 98.97\n",
      "==================== Valid Summary: Epoch 14 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.78\t Prec@1: 84.60\t Prec@5: 98.60\n",
      "Best Prec@1: 85.50 at epoch 12\n",
      "==================== Train Summary: Epoch 15 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.15\t Prec@1: 90.26\t Prec@5: 98.75\n",
      "==================== Valid Summary: Epoch 15 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 86.10\t Prec@5: 98.50\n",
      "Best Prec@1: 86.10 at epoch 15\n",
      "==================== Train Summary: Epoch 16 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.14\t Prec@1: 91.33\t Prec@5: 98.84\n",
      "==================== Valid Summary: Epoch 16 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 85.90\t Prec@5: 98.70\n",
      "Best Prec@1: 86.10 at epoch 15\n",
      "==================== Train Summary: Epoch 17 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.16\t Prec@1: 89.90\t Prec@5: 98.57\n",
      "==================== Valid Summary: Epoch 17 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.79\t Prec@1: 85.70\t Prec@5: 98.50\n",
      "Best Prec@1: 86.10 at epoch 15\n",
      "==================== Train Summary: Epoch 18 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.12\t Prec@1: 92.49\t Prec@5: 99.20\n",
      "==================== Valid Summary: Epoch 18 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.74\t Prec@1: 86.50\t Prec@5: 98.70\n",
      "Best Prec@1: 86.50 at epoch 18\n",
      "==================== Train Summary: Epoch 19 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.14\t Prec@1: 91.60\t Prec@5: 98.79\n",
      "==================== Valid Summary: Epoch 19 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.77\t Prec@1: 86.60\t Prec@5: 98.70\n",
      "Best Prec@1: 86.60 at epoch 19\n",
      "==================== Train Summary: Epoch 20 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.15\t Prec@1: 91.38\t Prec@5: 98.79\n",
      "==================== Valid Summary: Epoch 20 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.73\t Prec@1: 87.40\t Prec@5: 98.70\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 21 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.11\t Prec@1: 92.36\t Prec@5: 99.33\n",
      "==================== Valid Summary: Epoch 21 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 86.90\t Prec@5: 98.90\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 22 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.14\t Prec@1: 91.51\t Prec@5: 98.61\n",
      "==================== Valid Summary: Epoch 22 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 87.10\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 23 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.15\t Prec@1: 91.33\t Prec@5: 98.93\n",
      "==================== Valid Summary: Epoch 23 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 86.60\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 24 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.15\t Prec@1: 91.29\t Prec@5: 98.66\n",
      "==================== Valid Summary: Epoch 24 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 86.80\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 25 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.13\t Prec@1: 92.31\t Prec@5: 98.97\n",
      "==================== Valid Summary: Epoch 25 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.75\t Prec@1: 86.90\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 26 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.13\t Prec@1: 91.64\t Prec@5: 99.02\n",
      "==================== Valid Summary: Epoch 26 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.74\t Prec@1: 86.90\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 27 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.13\t Prec@1: 91.96\t Prec@5: 99.11\n",
      "==================== Valid Summary: Epoch 27 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.74\t Prec@1: 87.00\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 28 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.11\t Prec@1: 92.14\t Prec@5: 99.42\n",
      "==================== Valid Summary: Epoch 28 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.77\t Prec@1: 86.70\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 29 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.14\t Prec@1: 90.57\t Prec@5: 98.79\n",
      "==================== Valid Summary: Epoch 29 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.76\t Prec@1: 86.90\t Prec@5: 98.80\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "==================== Train Summary: Epoch 30 ====================\n",
      "Train Epoch Elapsed time: 00:00:02\n",
      "Loss: 0.15\t Prec@1: 91.06\t Prec@5: 98.79\n",
      "==================== Valid Summary: Epoch 30 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.73\t Prec@1: 86.90\t Prec@5: 98.70\n",
      "Best Prec@1: 87.40 at epoch 20\n",
      "Best per class results: [95.0, 93.0, 94.0, 95.0, 87.0, 85.0, 82.0, 90.0, 72.0, 81.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/top1</td><td>▁▅▅▅▆▆▆▇▇▆▇▇▇█▇█▇█████████████</td></tr><tr><td>train/top5</td><td>▁▅▆▆▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>valid/loss</td><td>█▇▅▅▂▄▂▂▂▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/top1</td><td>▁▃▃▅▆▅▆▆▆▃▇▇▇▇██▇█████████████</td></tr><tr><td>valid/top5</td><td>▁▂▄▄▇▃▇▃▆▆█▆▇▆▆▇▆▇▇▇█▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>0.14525</td></tr><tr><td>train/top1</td><td>91.06345</td></tr><tr><td>train/top5</td><td>98.79357</td></tr><tr><td>valid/loss</td><td>0.72816</td></tr><tr><td>valid/top1</td><td>86.9</td></tr><tr><td>valid/top5</td><td>98.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_places10_LT_balanced_softmax</strong> at: <a href='https://wandb.ai/alex4727/posco2023/runs/g0uiwy83' target=\"_blank\">https://wandb.ai/alex4727/posco2023/runs/g0uiwy83</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230711_220443-g0uiwy83/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"posco2023\", entity=\"alex4727\", name=run_name)\n",
    "\n",
    "# Main Loop\n",
    "best_top1, best_top1_epoch, best_per_class_results = 0, 0, None\n",
    "for epoch in range(total_epochs):\n",
    "    train(device, train_loader, model, criterion, optimizer, scheduler, epoch, turn_on_wandb=True)\n",
    "    top1, per_class_results = validate(device, valid_loader, model, criterion, epoch, turn_on_wandb=True)\n",
    "    if top1 > best_top1:\n",
    "        best_top1 = top1\n",
    "        best_top1_epoch = epoch+1\n",
    "        best_per_class_results = per_class_results\n",
    "        save_ckpt(epoch=epoch+1, model=model, per_class_results=per_class_results, run_name=run_name)\n",
    "        \n",
    "    print(f\"Best Prec@1: {best_top1:.2f} at epoch {best_top1_epoch}\", flush=True)\n",
    "\n",
    "# Print Best Results\n",
    "print(f\"Best per class results: {best_per_class_results}\", flush=True)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint resnet18_places10_LT_balanced_softmax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Valid Summary: Epoch 1 ====================\n",
      "Valid Elapsed time: 00:00:00\n",
      "Loss: 0.73\t Prec@1: 87.40\t Prec@5: 98.70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87.4, [95.0, 93.0, 94.0, 95.0, 87.0, 85.0, 82.0, 90.0, 72.0, 81.0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and testing\n",
    "model_for_eval = resnet18(num_classes=10).to(device)\n",
    "load_ckpt(model=model_for_eval, run_name=run_name)\n",
    "validate(device, valid_loader, model_for_eval, criterion, epoch=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
